{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - CIFAR with CNNs\n",
    "\n",
    "In this exercise, we will use convolutional neural networks to solve the CIFAR10 classification task.\n",
    "\n",
    "You need to load the data from PyTorch, build the appropriate network and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./cifar_data', train = True , download = True, transform = transform )\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10('./cifar_data', train = False, download = True, transform = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 4, shuffle = True)\n",
    "\n",
    "test_loader = train_loader = torch.utils.data.DataLoader(test_set, batch_size = 4, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'dear', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#check demension of train_dataset\n",
    " \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5) #input channel size is three because images have 3 colour channels, output = 6, kernel =5\n",
    "        self.pool = nn.MaxPool2d(2,2) # kernel side = 2 and stride = 2\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # input size\n",
    "        self.fc2 = nn.Linear(120,90)\n",
    "        self.fc3 = nn.Linear(90, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5) #the number of batches, input size\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = Net().to(device) #if GPU exists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss() #softmax is already includers\n",
    "optimizer = optimizer.SGD(neural_net.parameters(), lr = 0.01)\n",
    "\n",
    "total_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1ad60a21970>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 1.5631\n",
      "Loss: 1.6027\n",
      "Loss: 1.4576\n",
      "Loss: 1.2632\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = neural_net(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "source": [
    "Evaluating the model..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network: 47.5 %\nAccuracy of plane: 67.9 % \nAccuracy of car: 54.1 % \nAccuracy of bird: 35.1 % \nAccuracy of cat: 33.9 % \nAccuracy of dear: 22.7 % \nAccuracy of dog: 54.9 % \nAccuracy of frog: 36.2 % \nAccuracy of horse: 66.4 % \nAccuracy of ship: 59.7 % \nAccuracy of truck: 44.1 % \n"
     ]
    }
   ],
   "source": [
    "#this function ensures backward pass and parameter updates in not used \n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_correct_class = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = neural_net(images)\n",
    "        index, predicted = torch.max(outputs,1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "\n",
    "            if(label == pred):\n",
    "                n_correct_class[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    accuracy = 100.0 * n_correct/n_samples\n",
    "    print(f'Accuracy of the network: {accuracy} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        accuracy = 100.0 * n_correct_class[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {accuracy} % ' )\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - IMDB sentiment analysis dataset\n",
    "\n",
    "In this exercise, we will use an LSTM neural network to classify whether movie reviews from the IMDB dataset are positive or negative.\n",
    "\n",
    "You need to load the data from PyTorch, build the appropriate network and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}